{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing as pre\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "### Based on the following Data Exploration, these conclusions can be made:\n",
    "\n",
    "1. The given features are identical to a variable not given below.\n",
    "\n",
    "    f34, f35, f37, f38, f58, f86, f87, f88, f96, f97, f98, f106, f107, f108, f116, f117, f118, f126, f127, f128, f155, f156, f157, f165, f166, f167, f175, f176, f177, f185, f186, f187, f195, f196, f197, f225, f226, f227, f235, f236, f237, f245, f246, f247, f255, f256, f257, f265, f266, f267, f294, f295, f296, f302, f303, f304, f310, f311, f312, f318, f319, f320, f326, f327, f328, f345, f354, f362, f371, f379, f408, f417, f427, f457, f478, f488, f498, f508, f553, f563, f573, f582, f599, f678, f700, f701, f702, f729, f741, f764\n",
    "    \n",
    "    \n",
    "2. The following features are perfectly correlated.\n",
    "\n",
    "    f74  - f722; f676 - f765\n",
    "    \n",
    "    \n",
    "3. There is no one feature that has a high correlation with the target variable. The feature with the highest correlation has a score of 0.03985.\n",
    "\n",
    "\n",
    "4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(csv_path):\n",
    "    \"\"\"\n",
    "    Given a path to a file, reads in the data in the file\n",
    "    \"\"\"\n",
    "    print(\"Reading Data...\")\n",
    "    data = pd.read_csv(csv_path)\n",
    "    print(\"Shape:\", data.shape)\n",
    "    return data\n",
    "\n",
    "def clean_data(data):\n",
    "    \"\"\"\n",
    "    Cleans data by taking string based NAs and converting to NaN.\n",
    "    Assumes that the string columns are integer columns.\n",
    "    \"\"\"\n",
    "    print(\"Cleaning Data...\")\n",
    "    data = data.replace(\"NA\", None)\n",
    "    for col_name in data.select_dtypes(exclude=['int64', 'float64']).columns:\n",
    "        data[col_name] = pd.to_numeric(data[col_name], downcast=\"integer\", errors=\"coerce\")\n",
    "    return data\n",
    "\n",
    "def drop_duplicate_columns(data):\n",
    "    \"\"\"\n",
    "    Iterates through columns in dataframe to find columns\n",
    "    with identical values and compiles a single one of these columns into\n",
    "    a set of columns to be dropped.\n",
    "    \"\"\"\n",
    "    col_names = set() \n",
    "    for x in range(data.shape[1]): \n",
    "        col = data.iloc[:, x] \n",
    "        for y in range(x + 1, data.shape[1]):\n",
    "            check_dup = data.iloc[:, y] \n",
    "            if col.equals(check_dup): \n",
    "                col_names.add(data.columns.values[y]) \n",
    "    return data.drop(columns=list(col_names))\n",
    "\n",
    "def impute_values(data):\n",
    "    \"\"\"\n",
    "    Fits a simple imputer to the dataset and imputes missing\n",
    "    values in the dataset.\n",
    "    Might need to be changed to an iterative imputer.\n",
    "    \"\"\"\n",
    "    print(\"Imputing Missing Data...\")\n",
    "    matrix = data.to_numpy()\n",
    "    imp = SimpleImputer()\n",
    "    imp.fit(matrix)\n",
    "    complete_data = pd.DataFrame(imp.transform(matrix), columns=data.columns)\n",
    "    return complete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3249: DtypeWarning: Columns (135,204,274,417) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (105471, 771)\n"
     ]
    }
   ],
   "source": [
    "loan_data = impute_values(clean_data(read_data(\"train_v2.csv\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_data = drop_duplicate_columns(loan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105471, 681)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f34', 'f35', 'f37', 'f38', 'f58', 'f86', 'f87', 'f88', 'f96', 'f97',\n",
       "       'f98', 'f106', 'f107', 'f108', 'f116', 'f117', 'f118', 'f126', 'f127',\n",
       "       'f128', 'f155', 'f156', 'f157', 'f165', 'f166', 'f167', 'f175', 'f176',\n",
       "       'f177', 'f185', 'f186', 'f187', 'f195', 'f196', 'f197', 'f225', 'f226',\n",
       "       'f227', 'f235', 'f236', 'f237', 'f245', 'f246', 'f247', 'f255', 'f256',\n",
       "       'f257', 'f265', 'f266', 'f267', 'f294', 'f295', 'f296', 'f302', 'f303',\n",
       "       'f304', 'f310', 'f311', 'f312', 'f318', 'f319', 'f320', 'f326', 'f327',\n",
       "       'f328', 'f345', 'f354', 'f362', 'f371', 'f379', 'f408', 'f417', 'f427',\n",
       "       'f457', 'f478', 'f488', 'f498', 'f508', 'f553', 'f563', 'f573', 'f582',\n",
       "       'f599', 'f678', 'f700', 'f701', 'f702', 'f729', 'f741', 'f764'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.drop(columns=dropped_data.columns).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dropped_data.drop(\"loss\",1) # feature matrix\n",
    "y = dropped_data[\"loss\"] # target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f770</th>\n",
       "      <th>f771</th>\n",
       "      <th>f772</th>\n",
       "      <th>f773</th>\n",
       "      <th>f774</th>\n",
       "      <th>f775</th>\n",
       "      <th>f776</th>\n",
       "      <th>f777</th>\n",
       "      <th>f778</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>id</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042966</td>\n",
       "      <td>-0.018418</td>\n",
       "      <td>-0.004061</td>\n",
       "      <td>0.042855</td>\n",
       "      <td>-0.074279</td>\n",
       "      <td>0.048518</td>\n",
       "      <td>0.018368</td>\n",
       "      <td>0.041640</td>\n",
       "      <td>0.047053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000437</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>-0.001525</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>-0.002677</td>\n",
       "      <td>0.008294</td>\n",
       "      <td>0.005805</td>\n",
       "      <td>0.045460</td>\n",
       "      <td>-0.050143</td>\n",
       "      <td>0.000342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f1</td>\n",
       "      <td>0.042966</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.210388</td>\n",
       "      <td>-0.000370</td>\n",
       "      <td>0.782389</td>\n",
       "      <td>-0.269849</td>\n",
       "      <td>0.102250</td>\n",
       "      <td>-0.160220</td>\n",
       "      <td>-0.173839</td>\n",
       "      <td>0.972323</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081408</td>\n",
       "      <td>-0.044220</td>\n",
       "      <td>0.036631</td>\n",
       "      <td>-0.031180</td>\n",
       "      <td>0.003576</td>\n",
       "      <td>0.066611</td>\n",
       "      <td>0.078637</td>\n",
       "      <td>0.873927</td>\n",
       "      <td>-0.270134</td>\n",
       "      <td>-0.008231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f2</td>\n",
       "      <td>-0.018418</td>\n",
       "      <td>-0.210388</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>-0.215980</td>\n",
       "      <td>0.221009</td>\n",
       "      <td>0.091765</td>\n",
       "      <td>-0.131526</td>\n",
       "      <td>-0.155886</td>\n",
       "      <td>-0.248444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078232</td>\n",
       "      <td>-0.020417</td>\n",
       "      <td>0.044855</td>\n",
       "      <td>-0.063950</td>\n",
       "      <td>-0.023441</td>\n",
       "      <td>-0.175660</td>\n",
       "      <td>-0.097982</td>\n",
       "      <td>-0.225693</td>\n",
       "      <td>0.221553</td>\n",
       "      <td>-0.000588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f3</td>\n",
       "      <td>-0.004061</td>\n",
       "      <td>-0.000370</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>0.003789</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>-0.003279</td>\n",
       "      <td>-0.000905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>-0.002818</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>-0.003355</td>\n",
       "      <td>-0.005865</td>\n",
       "      <td>-0.001653</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>-0.000504</td>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f4</td>\n",
       "      <td>0.042855</td>\n",
       "      <td>0.782389</td>\n",
       "      <td>-0.215980</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.256425</td>\n",
       "      <td>0.119798</td>\n",
       "      <td>-0.231141</td>\n",
       "      <td>-0.209636</td>\n",
       "      <td>0.832383</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108024</td>\n",
       "      <td>-0.088417</td>\n",
       "      <td>0.085026</td>\n",
       "      <td>-0.082677</td>\n",
       "      <td>-0.025975</td>\n",
       "      <td>0.036907</td>\n",
       "      <td>0.038133</td>\n",
       "      <td>0.875710</td>\n",
       "      <td>-0.262051</td>\n",
       "      <td>-0.005019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f775</td>\n",
       "      <td>0.008294</td>\n",
       "      <td>0.066611</td>\n",
       "      <td>-0.175660</td>\n",
       "      <td>-0.005865</td>\n",
       "      <td>0.036907</td>\n",
       "      <td>-0.013851</td>\n",
       "      <td>-0.037364</td>\n",
       "      <td>0.035887</td>\n",
       "      <td>0.042992</td>\n",
       "      <td>0.068681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161132</td>\n",
       "      <td>0.241116</td>\n",
       "      <td>-0.253267</td>\n",
       "      <td>0.259700</td>\n",
       "      <td>0.250479</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.056518</td>\n",
       "      <td>0.020298</td>\n",
       "      <td>-0.017353</td>\n",
       "      <td>-0.007223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f776</td>\n",
       "      <td>0.005805</td>\n",
       "      <td>0.078637</td>\n",
       "      <td>-0.097982</td>\n",
       "      <td>-0.001653</td>\n",
       "      <td>0.038133</td>\n",
       "      <td>-0.036634</td>\n",
       "      <td>0.010537</td>\n",
       "      <td>0.029545</td>\n",
       "      <td>0.008010</td>\n",
       "      <td>0.088910</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229139</td>\n",
       "      <td>-0.218955</td>\n",
       "      <td>0.214578</td>\n",
       "      <td>-0.210643</td>\n",
       "      <td>-0.283690</td>\n",
       "      <td>-0.056518</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.118741</td>\n",
       "      <td>-0.043901</td>\n",
       "      <td>-0.015506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f777</td>\n",
       "      <td>0.045460</td>\n",
       "      <td>0.873927</td>\n",
       "      <td>-0.225693</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.875710</td>\n",
       "      <td>-0.303485</td>\n",
       "      <td>0.161654</td>\n",
       "      <td>-0.271501</td>\n",
       "      <td>-0.219554</td>\n",
       "      <td>0.929218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125933</td>\n",
       "      <td>-0.111692</td>\n",
       "      <td>0.108687</td>\n",
       "      <td>-0.106476</td>\n",
       "      <td>-0.056088</td>\n",
       "      <td>0.020298</td>\n",
       "      <td>0.118741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.304588</td>\n",
       "      <td>-0.004855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f778</td>\n",
       "      <td>-0.050143</td>\n",
       "      <td>-0.270134</td>\n",
       "      <td>0.221553</td>\n",
       "      <td>-0.000504</td>\n",
       "      <td>-0.262051</td>\n",
       "      <td>0.770800</td>\n",
       "      <td>-0.070763</td>\n",
       "      <td>0.124866</td>\n",
       "      <td>-0.003734</td>\n",
       "      <td>-0.284848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063802</td>\n",
       "      <td>0.046040</td>\n",
       "      <td>-0.042579</td>\n",
       "      <td>0.039952</td>\n",
       "      <td>0.042424</td>\n",
       "      <td>-0.017353</td>\n",
       "      <td>-0.043901</td>\n",
       "      <td>-0.304588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>loss</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>-0.000588</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>-0.005019</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>-0.003449</td>\n",
       "      <td>-0.001862</td>\n",
       "      <td>-0.003433</td>\n",
       "      <td>-0.006301</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004874</td>\n",
       "      <td>-0.005386</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>-0.005755</td>\n",
       "      <td>0.005902</td>\n",
       "      <td>-0.007223</td>\n",
       "      <td>-0.015506</td>\n",
       "      <td>-0.004855</td>\n",
       "      <td>0.003389</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>681 rows × 681 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id        f1        f2        f3        f4        f5        f6  \\\n",
       "id    1.000000  0.042966 -0.018418 -0.004061  0.042855 -0.074279  0.048518   \n",
       "f1    0.042966  1.000000 -0.210388 -0.000370  0.782389 -0.269849  0.102250   \n",
       "f2   -0.018418 -0.210388  1.000000  0.003149 -0.215980  0.221009  0.091765   \n",
       "f3   -0.004061 -0.000370  0.003149  1.000000  0.000040  0.002255  0.003789   \n",
       "f4    0.042855  0.782389 -0.215980  0.000040  1.000000 -0.256425  0.119798   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "f775  0.008294  0.066611 -0.175660 -0.005865  0.036907 -0.013851 -0.037364   \n",
       "f776  0.005805  0.078637 -0.097982 -0.001653  0.038133 -0.036634  0.010537   \n",
       "f777  0.045460  0.873927 -0.225693  0.000149  0.875710 -0.303485  0.161654   \n",
       "f778 -0.050143 -0.270134  0.221553 -0.000504 -0.262051  0.770800 -0.070763   \n",
       "loss  0.000342 -0.008231 -0.000588  0.000785 -0.005019  0.003902 -0.003449   \n",
       "\n",
       "            f7        f8        f9  ...      f770      f771      f772  \\\n",
       "id    0.018368  0.041640  0.047053  ... -0.000437  0.001546 -0.001525   \n",
       "f1   -0.160220 -0.173839  0.972323  ... -0.081408 -0.044220  0.036631   \n",
       "f2   -0.131526 -0.155886 -0.248444  ...  0.078232 -0.020417  0.044855   \n",
       "f3    0.001304 -0.003279 -0.000905  ...  0.001931  0.002581 -0.002818   \n",
       "f4   -0.231141 -0.209636  0.832383  ... -0.108024 -0.088417  0.085026   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "f775  0.035887  0.042992  0.068681  ...  0.161132  0.241116 -0.253267   \n",
       "f776  0.029545  0.008010  0.088910  ... -0.229139 -0.218955  0.214578   \n",
       "f777 -0.271501 -0.219554  0.929218  ... -0.125933 -0.111692  0.108687   \n",
       "f778  0.124866 -0.003734 -0.284848  ...  0.063802  0.046040 -0.042579   \n",
       "loss -0.001862 -0.003433 -0.006301  ... -0.004874 -0.005386  0.005567   \n",
       "\n",
       "          f773      f774      f775      f776      f777      f778      loss  \n",
       "id    0.001295 -0.002677  0.008294  0.005805  0.045460 -0.050143  0.000342  \n",
       "f1   -0.031180  0.003576  0.066611  0.078637  0.873927 -0.270134 -0.008231  \n",
       "f2   -0.063950 -0.023441 -0.175660 -0.097982 -0.225693  0.221553 -0.000588  \n",
       "f3    0.002964 -0.003355 -0.005865 -0.001653  0.000149 -0.000504  0.000785  \n",
       "f4   -0.082677 -0.025975  0.036907  0.038133  0.875710 -0.262051 -0.005019  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "f775  0.259700  0.250479  1.000000 -0.056518  0.020298 -0.017353 -0.007223  \n",
       "f776 -0.210643 -0.283690 -0.056518  1.000000  0.118741 -0.043901 -0.015506  \n",
       "f777 -0.106476 -0.056088  0.020298  0.118741  1.000000 -0.304588 -0.004855  \n",
       "f778  0.039952  0.042424 -0.017353 -0.043901 -0.304588  1.000000  0.003389  \n",
       "loss -0.005755  0.005902 -0.007223 -0.015506 -0.004855  0.003389  1.000000  \n",
       "\n",
       "[681 rows x 681 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Pearson Correlation\n",
    "cor = dropped_data.corr()\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correlation with output variable\n",
    "cor_target = abs(cor[\"loss\"])\n",
    "#Selecting highly correlated features\n",
    "relevant_features = cor_target[cor_target>=0.05]\n",
    "relevant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following features relate highly to f74\n",
      "f74     1.0\n",
      "f722    1.0\n",
      "Name: f74, dtype: float64\n",
      "Following features relate highly to f676\n",
      "f676    1.0\n",
      "f765    1.0\n",
      "Name: f676, dtype: float64\n",
      "Following features relate highly to f722\n",
      "f74     1.0\n",
      "f722    1.0\n",
      "Name: f722, dtype: float64\n",
      "Following features relate highly to f765\n",
      "f676    1.0\n",
      "f765    1.0\n",
      "Name: f765, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Correlation with output variable\n",
    "for i in cor.columns:\n",
    "    cor_target = abs(cor[i])\n",
    "    #Selecting highly correlated features\n",
    "    relevant_features = cor_target[cor_target>=1.0]\n",
    "    if (len(relevant_features) > 1):\n",
    "        print(\"Following features relate highly to\", i)\n",
    "        print(relevant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.039848841246689616"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(cor[\"loss\"])[:-1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
